---
title: Challenges and limitations of LLM-s
layout: default
nav_order: 6
---

# Challenges and limitations of LLM-s


While LLM-s have many advantages and may be used for different positive purposes, they also come with their own challenges and limitations like:

- **bias** - depending on what is in the data the LLM-s were trained on, the possible answers may be biased or even discriminatory.
- **misinformation and hallucinations** - LLM-s may generate false or misleading information. It can have a serious impact especially in fields like healthcare, engineering or law since they require high levels of accuracy and can seriously influence people's lives.
- **information leaks** - since LLM-s are trained on vast amounts of data, they may contain also private data and sensitive information.
- **stale data** - if LLM-s don't have access to real-time facts and events, the generated answers are only as up-to-date as the training data they were trained on.
- **plagiarism** -  LLM-s are prone to pick content without knowing where it was initially created, thus they may violate copyright and intellectual property.
- **lack of transparency and explainability** - LLM-s often function like a black box with hidden decision making process where it is not traceable how they actually arrived at certain outputs.
- **glitch tokens** - LLM-s may contain glitch tokens which are specific words or strings that cause them to behave in unexpected and often nonsensical ways, for example repeat certain phrases not related to the question. 
- **impact on the environment** - developing LLM-s requires considerable computational resources, which causes energy consumption and a large carbon footprint.
- **skill degradation** - if not used properly, LLM-s may contribute to skill reduction in students who rely overly on LLMs for example for writing essays, which in turn decreases their learning and writing skills.
- **job displacement** - innovations like LLM-s and, more generally, AI will drastically change or replace some of the job roles.
- **lack of accountability** - as LLM-s become more advanced, it will be more challenging to attribute who should be held accountable for the potential harmful outputs they produce.
- **ethical considerations** - LLM-s may be used to manipulate or deceive people, for example through creating deepfakes, phishing attacks or social engineering schemes.