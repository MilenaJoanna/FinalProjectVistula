---
title: Challenges and limitations of LLM-s
layout: default
nav_order: 6
---

# Challenges and limitations of LLM-s

<p style= "padding: 35px 25px 5px;">While LLM-s have many advantages and may be used for different positive purposes, they also come with their own challenges and limitations like:</p>

- **misinformation and hallucinations** - LLM-s may generate false or misleading information. That can have a serious impact especially in fields like healthcare, engineering or law, which require high levels of accuracy. Generating and publishing factually incorrect content can put at risk people's lives or health, or cause costly damage to equipment.
- **stale data** - if LLM-s don't have access to real-time facts and events, the generated answers are only as up-to-date as the training data they were trained on.
- **bias** - depending on what is in the data the LLM-s were trained on, the possible answers may be biased or even discriminatory, or apply only to the parts of the world where the majority of training data was harvested.
- **glitch tokens** - LLM-s may contain glitch tokens which are specific words or strings that cause them to behave in unexpected and often nonsensical ways, for example repeat certain phrases not related to the question.
- **lack of transparency and explainability** - LLM-s often function like a black box with hidden decision making process where it is not traceable how they actually arrived at certain outputs.
- **information leaks** - since LLM-s are trained on vast amounts of data, they may contain also private data and sensitive information.
- **plagiarism** - LLM-s are prone to pick content without tracking where it was initially created, thus they may violate copyright and intellectual property.
- **lack of accountability** - as LLM-s become more advanced, it is more challenging to attribute who should be held accountable for the potential harmful outputs they produce.
- **unethical use** - LLM-s may be used to manipulate or deceive people, for example through creating deepfakes, phishing attacks or social engineering schemes.
- **skill degradation** - if not used properly, LLM-s may contribute to skill reduction in students and employees who rely overly on LLMs for writing content or code, which in turn decreases their learning, writing and programming skills.
- **job displacement** - innovations like LLM-s and, more generally, AI are expected to drastically change or replace some of the job roles.
- **impact on the environment** - developing LLM-s requires considerable computational resources, which causes energy consumption and a large carbon footprint.
